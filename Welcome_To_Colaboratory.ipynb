{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varuncs2011/rl/blob/master/Welcome_To_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>What is Colaboratory?</h1>\n",
        "\n",
        "Colaboratory, or \"Colab\" for short, allows you to write and execute Python in your browser, with \n",
        "- Zero configuration required\n",
        "- Free access to GPUs\n",
        "- Easy sharing\n",
        "\n",
        "Whether you're a **student**, a **data scientist** or an **AI researcher**, Colab can make your work easier. Watch [Introduction to Colab](https://www.youtube.com/watch?v=inN8seMm7UI) to learn more, or just get started below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvgc7Y-Gkx0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import itertools\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "new_game = 'http://codingforfun.pmdx.me/v2/new'\n",
        "make_move = 'http://codingforfun.pmdx.me/v2/play'\n",
        "\n",
        "class Game:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.action_space = {}\n",
        "        self.num_actions = 9\n",
        "        self.game_code = \"\"\n",
        "        self.robot_says = 0\n",
        "        self.epsilon = 0.1\n",
        "\n",
        "    def restart_game(self):\n",
        "        resp = requests.post(url=new_game)\n",
        "        self.game_code = resp.json()['game_code']\n",
        "        self.robot_says = resp.json()['robot_says']\n",
        "\n",
        "    def createEpsilonGreedyPolicy(self, Q, state, prev_action):\n",
        "\n",
        "\n",
        "        action_probabilities = np.ones(9, dtype=float) * self.epsilon / self.num_actions\n",
        "\n",
        "        best_action = np.argmax(Q[state][prev_action])\n",
        "        action_probabilities[best_action] += (1.0 - self.epsilon)\n",
        "        return action_probabilities\n",
        "\n",
        "\n",
        "    def qlearning(self, num_episodes, discount_factor=0.91, alpha=0.6):\n",
        "\n",
        "\n",
        "        # state -> (action -> action-value).\n",
        "        Q = defaultdict(lambda: np.zeros((self.num_actions, self.num_actions)))\n",
        "\n",
        "\n",
        "        # For every episode\n",
        "        for i_episode in range(num_episodes):\n",
        "            if i_episode > 1200:\n",
        "                self.epsilon = 0\n",
        "\n",
        "            # Reset the environment and pick the first action\n",
        "            self.restart_game()\n",
        "            prev_action = 0\n",
        "\n",
        "            for _ in itertools.count():\n",
        "\n",
        "\n",
        "                state = self.robot_says\n",
        "                # get probabilities of all actions from current state\n",
        "                action_probabilities = self.createEpsilonGreedyPolicy(Q, state, prev_action)\n",
        "\n",
        "                # choose action according to\n",
        "                # the probability distribution\n",
        "                action = np.random.choice(np.arange(len(action_probabilities)), p=action_probabilities)\n",
        "\n",
        "                # take action and get reward, transit to next state\n",
        "                next_state, reward, done = self.step(action)\n",
        "\n",
        "                # TD Update\n",
        "                best_next_action = np.argmax(Q[next_state][action])\n",
        "                td_target = reward + discount_factor * Q[next_state][action][best_next_action]\n",
        "                td_delta = td_target - Q[state][prev_action][action]\n",
        "                Q[state][prev_action][action] += alpha * td_delta\n",
        "\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "                prev_action = action\n",
        "        return Q\n",
        "\n",
        "    def step(self, action):\n",
        "        params = {\n",
        "            \"game_code\": self.game_code,\n",
        "            \"agent_says\": int(action+1)\n",
        "        }\n",
        "        resp = requests.post(url=make_move, json=params)\n",
        "        agent_rounds = resp.json()['agent_rounds']\n",
        "        robot_rounds = resp.json()['robot_rounds']\n",
        "\n",
        "        current_round = str(resp.json()['outcome']).split(\" \")[0]\n",
        "        done = False\n",
        "\n",
        "        if agent_rounds == 5 or robot_rounds == 5:\n",
        "            done = True\n",
        "            robot_says = 0\n",
        "        else:\n",
        "            robot_says = resp.json()['robot_says']\n",
        "\n",
        "        if current_round == 'Agent':\n",
        "            return int(robot_says), 1, done\n",
        "        else:\n",
        "            return int(robot_says), -1, done\n",
        "\n",
        "\n",
        "run = Game()\n",
        "Q  = run.qlearning(1500)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aplKZdz2uUqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b5a1ac64-d07c-4453-9353-2165a6dc8837"
      },
      "source": [
        "class Game1:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.action_space = {}\n",
        "        self.num_actions = 9\n",
        "        self.game_code = \"\"\n",
        "        self.robot_says = 0\n",
        "        self.epsilon = 0.1\n",
        "        self.agent_wins = 0\n",
        "        self.robot_wins = 0\n",
        "\n",
        "    def restart_gamet(self):\n",
        "        resp = requests.post(url=new_game)\n",
        "        self.game_code = resp.json()['game_code']\n",
        "        self.robot_says = resp.json()['robot_says']\n",
        "\n",
        "    def createEpsilonGreedyPolicyt(self, Q, state, prev_action):\n",
        "\n",
        "        action_probabilities = np.ones(9, dtype=float) * self.epsilon / self.num_actions\n",
        "\n",
        "        best_action = np.argmax(Q[state][prev_action])\n",
        "        action_probabilities[best_action] += (1.0 - self.epsilon)\n",
        "        return action_probabilities\n",
        "\n",
        "    def qlearningt(self, Q_Value, num_episodes, discount_factor=0.91, alpha=0.6):\n",
        "\n",
        "\n",
        "        # state -> (action -> action-value).\n",
        "        Q = Q_Value\n",
        "\n",
        "\n",
        "        arr_reward = []\n",
        "        # For every episode\n",
        "        for i_episode in range(num_episodes):\n",
        "            self.epsilon = 0\n",
        "\n",
        "            # Reset the environment and pick the first action\n",
        "            self.restart_gamet()\n",
        "            prev_action = 0\n",
        "\n",
        "            for _ in itertools.count():\n",
        "\n",
        "\n",
        "                state = self.robot_says\n",
        "                # get probabilities of all actions from current state\n",
        "                action_probabilities = self.createEpsilonGreedyPolicyt(Q, state, prev_action)\n",
        "\n",
        "                # choose action according to\n",
        "                # the probability distribution\n",
        "                action = np.random.choice(np.arange(len(action_probabilities)), p=action_probabilities)\n",
        "\n",
        "                # take action and get reward, transit to next state\n",
        "                next_state, reward, done = self.stept(action)\n",
        "\n",
        "                arr_reward.append(reward)\n",
        "\n",
        "                # TD Update\n",
        "                best_next_action = np.argmax(Q[next_state][action])\n",
        "                td_target = reward + discount_factor * Q[next_state][action][best_next_action]\n",
        "                td_delta = td_target - Q[state][prev_action][action]\n",
        "                Q[state][prev_action][action] += alpha * td_delta\n",
        "\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "                prev_action = action\n",
        "        print(\"Agent \"+ str(self.agent_wins))\n",
        "        print(\"Robot \"+ str(self.robot_wins))\n",
        "        \n",
        "    def stept(self, action):\n",
        "        params = {\n",
        "            \"game_code\": self.game_code,\n",
        "            \"agent_says\": int(action+1)\n",
        "        }\n",
        "        resp = requests.post(url=make_move, json=params)\n",
        "        agent_rounds = resp.json()['agent_rounds']\n",
        "        robot_rounds = resp.json()['robot_rounds']\n",
        "\n",
        "        current_round = str(resp.json()['outcome']).split(\" \")[0]\n",
        "        done = False\n",
        "\n",
        "        if agent_rounds == 5 or robot_rounds == 5:\n",
        "            done = True\n",
        "            robot_says = 0\n",
        "            if current_round=='Robot':\n",
        "              self.robot_wins += 1\n",
        "            else:\n",
        "              self.agent_wins += 1\n",
        "        else:\n",
        "            robot_says = resp.json()['robot_says']\n",
        "\n",
        "        if current_round == 'Agent':\n",
        "            return int(robot_says), 1, done\n",
        "        else:\n",
        "            return int(robot_says), -1, done\n",
        "\n",
        "run = Game1()\n",
        "run.qlearningt(Q, 200)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agent 200\n",
            "Robot 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6CEoPBBDFzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d8673a0-c12d-4d19-b8ce-e3bc8d114024"
      },
      "source": [
        "import pandas\n",
        "\n",
        "temp = dict(Q)\n",
        "row_labels = ['1', '2', '3', '4','5', '6', '7', '8','9']\n",
        "column_labels = ['1', '2', '3', '4','5', '6', '7', '8','9']\n",
        "\n",
        "for key, value in temp.items():\n",
        "  print(key)\n",
        "  print(\"***\")\n",
        "  for t in itertools.count():\n",
        "    print(str(t) + \":\" + str(value[t].argmax()))\n",
        "    if t==8:\n",
        "      break\n",
        "    \n",
        "\n",
        "  \n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "***\n",
            "0:8\n",
            "1:6\n",
            "2:1\n",
            "3:8\n",
            "4:0\n",
            "5:8\n",
            "6:8\n",
            "7:0\n",
            "8:0\n",
            "4\n",
            "***\n",
            "0:8\n",
            "1:7\n",
            "2:6\n",
            "3:5\n",
            "4:5\n",
            "5:4\n",
            "6:0\n",
            "7:0\n",
            "8:0\n",
            "3\n",
            "***\n",
            "0:8\n",
            "1:7\n",
            "2:4\n",
            "3:2\n",
            "4:2\n",
            "5:0\n",
            "6:3\n",
            "7:2\n",
            "8:0\n",
            "0\n",
            "***\n",
            "0:0\n",
            "1:0\n",
            "2:0\n",
            "3:0\n",
            "4:0\n",
            "5:0\n",
            "6:0\n",
            "7:0\n",
            "8:0\n",
            "2\n",
            "***\n",
            "0:8\n",
            "1:8\n",
            "2:5\n",
            "3:6\n",
            "4:5\n",
            "5:3\n",
            "6:2\n",
            "7:2\n",
            "8:0\n",
            "5\n",
            "***\n",
            "0:8\n",
            "1:5\n",
            "2:0\n",
            "3:3\n",
            "4:7\n",
            "5:4\n",
            "6:8\n",
            "7:0\n",
            "8:0\n",
            "6\n",
            "***\n",
            "0:8\n",
            "1:7\n",
            "2:4\n",
            "3:4\n",
            "4:8\n",
            "5:1\n",
            "6:1\n",
            "7:3\n",
            "8:0\n",
            "8\n",
            "***\n",
            "0:8\n",
            "1:6\n",
            "2:8\n",
            "3:8\n",
            "4:7\n",
            "5:8\n",
            "6:4\n",
            "7:0\n",
            "8:0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}